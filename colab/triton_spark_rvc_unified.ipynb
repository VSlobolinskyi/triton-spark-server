{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Triton Spark TTS + RVC Voice Conversion (Unified Container)\n",
    "\n",
    "This notebook runs the full pipeline with **both services inside a single udocker container**:\n",
    "1. **Triton Spark TTS** - Text-to-Speech (internal gRPC, port 8001)\n",
    "2. **RVC Voice Conversion** - Voice cloning (inline processing)\n",
    "3. **Voice HTTP API** - Unified endpoint (port 8003)\n",
    "\n",
    "## Architecture\n",
    "```\n",
    "┌─────────────────────────────────────────────────────────┐\n",
    "│  udocker Container                                      │\n",
    "│  ┌─────────────────┐    ┌─────────────────────────────┐ │\n",
    "│  │ Triton Server   │◄───│ Voice HTTP API (:8003)      │ │\n",
    "│  │ (Spark TTS)     │    │ - FastAPI wrapper           │ │\n",
    "│  │ :8001 gRPC      │    │ - TTS + RVC combined        │ │\n",
    "│  │ (internal)      │    │ - N parallel RVC workers    │ │\n",
    "│  └─────────────────┘    └─────────────────────────────┘ │\n",
    "└─────────────────────────────────────────────────────────┘\n",
    "                                   ▲\n",
    "                                   │ HTTP\n",
    "                                   ▼\n",
    "                            Host Python\n",
    "                         (simple requests)\n",
    "```\n",
    "\n",
    "## Port Allocation\n",
    "- `8000` - Triton HTTP (internal)\n",
    "- `8001` - Triton gRPC (internal)\n",
    "- `8002` - Triton Metrics (internal)\n",
    "- `8003` - Voice HTTP API (external)\n",
    "\n",
    "## API Endpoints\n",
    "- `POST /synthesize` - Full TTS + RVC pipeline\n",
    "- `POST /synthesize/stream` - Streaming audio response\n",
    "- `POST /tts` - TTS only\n",
    "- `POST /rvc` - RVC only\n",
    "- `GET /health` - Health check\n",
    "- `GET /status` - Detailed status\n",
    "\n",
    "## Benefits\n",
    "- Simple HTTP interface (no gRPC complexity on host)\n",
    "- Both services share CUDA context inside container\n",
    "- Single container to manage\n",
    "- No GPU memory fragmentation\n",
    "\n",
    "## Requirements\n",
    "- Google Colab with GPU runtime (T4 minimum, A100 recommended)\n",
    "- ~12GB disk space for models and dependencies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Section 1: Setup Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 1.1: Initialize udocker\n",
    "import os\n",
    "\n",
    "def udocker_init():\n",
    "    if not os.path.exists(\"/home/user\"):\n",
    "        !pip install udocker > /dev/null\n",
    "        !udocker --allow-root install > /dev/null\n",
    "        !useradd -m user > /dev/null\n",
    "    print('udocker initialized')\n",
    "\n",
    "udocker_init()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 1.2: Clone repository\n",
    "!git clone https://github.com/VSlobolinskyi/triton-spark-server.git\n",
    "%cd triton-spark-server\n",
    "!git checkout feature/rvc-integration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 1.3: GPU Configuration for udocker\n",
    "import subprocess\n",
    "\n",
    "def detect_gpu_paths():\n",
    "    paths = {}\n",
    "    paths['nvidia_smi'] = subprocess.getoutput('which nvidia-smi')\n",
    "    paths['cuda_dir'] = subprocess.getoutput(\"find /usr -path '*/cuda*' -type d -maxdepth 3 | grep -v 'targets' | head -1\")\n",
    "    paths['nvidia_lib_dir'] = subprocess.getoutput(\"find /usr -name 'libcuda.so*' -o -name 'libnvidia-ml.so*' | grep -v 'stubs' | xargs dirname | sort -u | head -1\")\n",
    "    paths['ld_library_path'] = f\"{paths['nvidia_lib_dir']}:{paths['cuda_dir']}/lib64:{paths['cuda_dir']}/compat\"\n",
    "\n",
    "    basic_devices = ['/dev/nvidia0', '/dev/nvidiactl', '/dev/nvidia-uvm']\n",
    "\n",
    "    volumes = [\n",
    "        f\"--volume={paths['nvidia_smi']}:{paths['nvidia_smi']}\",\n",
    "        f\"--volume={paths['nvidia_lib_dir']}:{paths['nvidia_lib_dir']}\",\n",
    "        f\"--volume={paths['cuda_dir']}:{paths['cuda_dir']}\"\n",
    "    ]\n",
    "\n",
    "    for device in basic_devices:\n",
    "        if os.path.exists(device):\n",
    "            volumes.append(f\"--volume={device}:{device}\")\n",
    "\n",
    "    env_vars = [\n",
    "        f\"--env=LD_LIBRARY_PATH={paths['ld_library_path']}:/usr/local/tensorrt/targets/x86_64-linux-gnu/lib:$LD_LIBRARY_PATH\",\n",
    "        f\"--env=PATH=/opt/tritonserver/bin:{paths['cuda_dir']}/bin:/usr/bin:$PATH\",\n",
    "        \"--env=NVIDIA_VISIBLE_DEVICES=all\",\n",
    "        \"--env=NVIDIA_DRIVER_CAPABILITIES=compute,utility\"\n",
    "    ]\n",
    "\n",
    "    return {\n",
    "        'paths': paths,\n",
    "        'volumes': volumes,\n",
    "        'env_vars': env_vars,\n",
    "        'all_options': ' '.join(volumes + env_vars)\n",
    "    }\n",
    "\n",
    "gpu_config = detect_gpu_paths()\n",
    "print(\"GPU configuration ready\")\n",
    "for k, v in gpu_config['paths'].items():\n",
    "    print(f\"  {k}: {v}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Section 2: Setup Container with TTS + RVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 2.1: Pull Triton Server image\n",
    "!udocker --allow-root pull nvcr.io/nvidia/tritonserver:25.02-trtllm-python-py3\n",
    "!udocker --allow-root create --name=voice_server nvcr.io/nvidia/tritonserver:25.02-trtllm-python-py3\n",
    "!udocker --allow-root setup --nvidia voice_server"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 2.2: Install TTS dependencies (torchaudio, etc.)\n",
    "import os\n",
    "pwd = os.getcwd()\n",
    "\n",
    "tts_deps_cmd = f'''udocker --allow-root run \\\n",
    "    --hostauth --hostenv \\\n",
    "    {gpu_config['all_options']} \\\n",
    "    --volume={pwd}:/workspace \\\n",
    "    voice_server \\\n",
    "    /bin/bash -c \"apt-get update && apt-get install -y cmake curl ffmpeg && \\\n",
    "git clone https://github.com/pytorch/audio.git && cd audio && git checkout c670ad8 && USE_FFMPEG=0 PATH=/usr/local/cuda/bin:\\$PATH python3 setup.py develop && \\\n",
    "pip install einx==0.3.0 omegaconf==2.3.0 soundfile==0.12.1 soxr==0.5.0.post1 tritonclient librosa 'huggingface-hub>=0.24.0,<1.0'\"\n",
    "'''\n",
    "\n",
    "!{tts_deps_cmd}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 2.3: Install RVC + HTTP API dependencies inside container\n",
    "import os\n",
    "pwd = os.getcwd()\n",
    "\n",
    "rvc_deps_cmd = f'''udocker --allow-root run \\\n",
    "    --hostauth --hostenv \\\n",
    "    {gpu_config['all_options']} \\\n",
    "    --volume={pwd}:/workspace \\\n",
    "    voice_server \\\n",
    "    /bin/bash -c \"pip install --no-cache-dir \\\n",
    "        faiss-cpu>=1.7.0 \\\n",
    "        pyworld==0.3.2 \\\n",
    "        praat-parselmouth>=0.4.2 \\\n",
    "        torchcrepe==0.0.23 \\\n",
    "        ffmpeg-python>=0.2.0 \\\n",
    "        av>=9.0.0 \\\n",
    "        onnxruntime-gpu>=1.13.0 \\\n",
    "        numba>=0.56.0 \\\n",
    "        joblib>=1.1.0 \\\n",
    "        fastapi>=0.100.0 \\\n",
    "        uvicorn>=0.21.1 \\\n",
    "        python-multipart>=0.0.6 && \\\n",
    "    pip install --no-cache-dir git+https://github.com/One-sixth/fairseq.git\"\n",
    "'''\n",
    "\n",
    "print(\"Installing RVC + HTTP API dependencies in container...\")\n",
    "!{rvc_deps_cmd}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 2.4: Build TensorRT-LLM engine for Spark TTS\n",
    "import os\n",
    "pwd = os.getcwd()\n",
    "\n",
    "build_cmd = f'''udocker --allow-root run \\\n",
    "    --hostauth --hostenv \\\n",
    "    {gpu_config['all_options']} \\\n",
    "    --env=PYTHONPATH=/workspace \\\n",
    "    --volume={pwd}:/workspace \\\n",
    "    voice_server \\\n",
    "    /bin/bash -c \"cd /workspace/triton && bash run.sh 0 2 offline\"'''\n",
    "\n",
    "print(\"Building TensorRT engine for Spark TTS...\")\n",
    "!{build_cmd}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Section 3: Download Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 3.1: Download RVC assets (HuBERT, RMVPE) - run inside container\n",
    "import os\n",
    "pwd = os.getcwd()\n",
    "\n",
    "assets_cmd = f'''udocker --allow-root run \\\n",
    "    --hostauth --hostenv \\\n",
    "    {gpu_config['all_options']} \\\n",
    "    --env=PYTHONPATH=/workspace \\\n",
    "    --volume={pwd}:/workspace \\\n",
    "    voice_server \\\n",
    "    /bin/bash -c \"cd /workspace && python3 tools/download_all_assets.py --rvc-only\"'''\n",
    "\n",
    "print(\"Downloading RVC assets...\")\n",
    "!{assets_cmd}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 3.2: Download RVC voice model\n",
    "import os\n",
    "pwd = os.getcwd()\n",
    "\n",
    "RVC_MODEL_URL = \"https://huggingface.co/Juneuarie/SilverWolfEN/resolve/main/SilverWolf.zip?download=true\"\n",
    "\n",
    "model_cmd = f'''udocker --allow-root run \\\n",
    "    --hostauth --hostenv \\\n",
    "    {gpu_config['all_options']} \\\n",
    "    --env=PYTHONPATH=/workspace \\\n",
    "    --volume={pwd}:/workspace \\\n",
    "    voice_server \\\n",
    "    /bin/bash -c \"cd /workspace && python3 tools/download_all_assets.py --rvc-model '{RVC_MODEL_URL}'\"'''\n",
    "\n",
    "print(\"Downloading RVC voice model...\")\n",
    "!{model_cmd}\n",
    "\n",
    "# List downloaded models and index files\n",
    "print(\"\\n=== Downloaded Files ===\")\n",
    "print(\"\\nVoice models (.pth):\")\n",
    "!ls -la assets/weights/*.pth 2>/dev/null || echo \"  No .pth files found in assets/weights/\"\n",
    "\n",
    "print(\"\\nIndex files (.index) - REQUIRED for voice quality:\")\n",
    "!ls -la logs/*.index 2>/dev/null || echo \"  WARNING: No .index files found in logs/\"\n",
    "!ls -la assets/*.index 2>/dev/null || echo \"\"\n",
    "\n",
    "# Check if index exists\n",
    "import glob\n",
    "index_files = glob.glob(\"logs/*.index\") + glob.glob(\"assets/*.index\")\n",
    "if not index_files:\n",
    "    print(\"\\n*** WARNING: No index file found! Voice quality enhancement will be disabled. ***\")\n",
    "    print(\"The RVC model zip should contain a .index file for best results.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Section 4: Start Voice Services"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 4.1: Start Voice HTTP API (Triton + RVC inside container)\n",
    "import subprocess\n",
    "import time\n",
    "import os\n",
    "\n",
    "pwd = os.getcwd()\n",
    "\n",
    "# Configuration\n",
    "RVC_MODEL = \"SilverWolf_e300_s6600.pth\"\n",
    "RVC_WORKERS = 2  # 2 for T4, up to 4 for A100\n",
    "API_PORT = 8003  # Triton uses 8000-8002, so we use 8003\n",
    "\n",
    "# Start services via startup script\n",
    "# NOTE: RVC requires these environment variables for model loading:\n",
    "#   - rmvpe_root: Path to rmvpe.pt for pitch extraction\n",
    "#   - hubert_base_path: Path to hubert_base.pt for feature extraction\n",
    "#   - weight_root: Path to RVC voice model weights\n",
    "#   - index_root: Path to .index files for voice quality enhancement\n",
    "server_cmd = f'''udocker --allow-root run \\\n",
    "    --hostauth --hostenv \\\n",
    "    {gpu_config['all_options']} \\\n",
    "    --env=PYTHONPATH=/workspace \\\n",
    "    --env=RVC_MODEL={RVC_MODEL} \\\n",
    "    --env=RVC_WORKERS={RVC_WORKERS} \\\n",
    "    --env=API_PORT={API_PORT} \\\n",
    "    --env=rmvpe_root=/workspace/assets/rmvpe \\\n",
    "    --env=hubert_base_path=/workspace/assets/hubert/hubert_base.pt \\\n",
    "    --env=weight_root=/workspace/assets/weights \\\n",
    "    --env=index_root=/workspace/logs \\\n",
    "    --volume={pwd}:/workspace \\\n",
    "    voice_server \\\n",
    "    /bin/bash /workspace/scripts/start_services.sh'''\n",
    "\n",
    "# Run in background\n",
    "process = subprocess.Popen(\n",
    "    f\"nohup {server_cmd} > services_log.txt 2>&1 &\",\n",
    "    shell=True\n",
    ")\n",
    "\n",
    "print(\"Starting voice services...\")\n",
    "print(f\"  Voice HTTP API: http://localhost:{API_PORT}\")\n",
    "print(f\"  RVC Workers: {RVC_WORKERS}\")\n",
    "print(f\"  RVC Model: {RVC_MODEL}\")\n",
    "print(\"\\nWaiting 150 seconds for services to initialize...\")\n",
    "time.sleep(150)\n",
    "\n",
    "print(\"\\nService logs:\")\n",
    "!tail -50 services_log.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 4.2: Install host Python dependencies (just requests + audio)\n",
    "!pip install -q requests soundfile numpy\n",
    "\n",
    "print(\"Host dependencies installed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 4.3: Test connection to Voice HTTP API\n",
    "import requests\n",
    "\n",
    "API_URL = \"http://localhost:8003\"\n",
    "\n",
    "print(\"Testing Voice HTTP API connection...\")\n",
    "\n",
    "# Health check\n",
    "try:\n",
    "    response = requests.get(f\"{API_URL}/health\", timeout=10)\n",
    "    if response.status_code == 200:\n",
    "        health = response.json()\n",
    "        print(f\"  Health: {health['status']}\")\n",
    "        print(f\"  Triton ready: {health.get('triton_ready', 'N/A')}\")\n",
    "        print(f\"  RVC ready: {health.get('rvc_ready', 'N/A')}\")\n",
    "    else:\n",
    "        print(f\"  Health check failed: {response.status_code}\")\n",
    "except requests.exceptions.RequestException as e:\n",
    "    print(f\"  Connection error: {e}\")\n",
    "\n",
    "# Detailed status\n",
    "print(\"\\nDetailed status:\")\n",
    "try:\n",
    "    response = requests.get(f\"{API_URL}/status\", timeout=10)\n",
    "    if response.status_code == 200:\n",
    "        status = response.json()\n",
    "        print(f\"  RVC Model: {status.get('rvc_model', 'N/A')}\")\n",
    "        print(f\"  RVC Workers: {status.get('rvc_workers', 'N/A')}\")\n",
    "        print(f\"  Triton address: {status.get('triton_addr', 'N/A')}:{status.get('triton_port', 'N/A')}\")\n",
    "except requests.exceptions.RequestException as e:\n",
    "    print(f\"  Status check failed: {e}\")\n",
    "\n",
    "print(\"\\nGPU memory usage:\")\n",
    "!nvidia-smi --query-gpu=memory.used,memory.total --format=csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Section 5: Upload Reference Audio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 5.1: Upload reference audio\n",
    "import os\n",
    "import soundfile as sf\n",
    "from google.colab import files\n",
    "\n",
    "!mkdir -p references TEMP/output\n",
    "\n",
    "print(\"Please upload a reference audio file (.wav format):\")\n",
    "uploaded = files.upload()\n",
    "\n",
    "reference_audio = list(uploaded.keys())[0]\n",
    "references_path = os.path.join(\"references\", reference_audio)\n",
    "\n",
    "with open(references_path, \"wb\") as f:\n",
    "    f.write(uploaded[reference_audio])\n",
    "\n",
    "audio, sr = sf.read(references_path)\n",
    "print(f\"Saved: {references_path} ({len(audio)/sr:.2f}s @ {sr}Hz)\")\n",
    "\n",
    "# Resample to 16kHz if needed\n",
    "if sr != 16000:\n",
    "    base_name = os.path.splitext(reference_audio)[0]\n",
    "    reference_audio_16k = os.path.join(\"references\", f\"{base_name}_16k.wav\")\n",
    "    !ffmpeg -y -i \"{references_path}\" -ar 16000 \"{reference_audio_16k}\" -loglevel error\n",
    "    print(f\"Resampled to 16kHz: {reference_audio_16k}\")\n",
    "else:\n",
    "    reference_audio_16k = references_path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Section 6: Run Voice Synthesis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 6.1: Synthesize with HTTP API (full pipeline)\n",
    "import requests\n",
    "import time\n",
    "import io\n",
    "\n",
    "API_URL = \"http://localhost:8003\"\n",
    "\n",
    "# Configuration\n",
    "TEXT = \"Hello! This is a test of the unified voice synthesis pipeline. Both TTS and RVC are running inside a single container, exposed via a simple HTTP API.\"\n",
    "REFERENCE_TEXT = \"\"\n",
    "PITCH_SHIFT = 0\n",
    "F0_METHOD = \"rmvpe\"\n",
    "INDEX_RATE = 1.0  # Use 1.0 for maximum quality enhancement\n",
    "\n",
    "print(f\"Text: {TEXT[:60]}...\")\n",
    "print(f\"Reference: {reference_audio_16k}\")\n",
    "print(f\"Settings: pitch={PITCH_SHIFT}, f0={F0_METHOD}, index_rate={INDEX_RATE}\")\n",
    "\n",
    "# Prepare request\n",
    "with open(reference_audio_16k, \"rb\") as f:\n",
    "    ref_audio_data = f.read()\n",
    "\n",
    "# Call synthesize endpoint\n",
    "print(\"\\nRunning TTS + RVC synthesis...\")\n",
    "start_time = time.time()\n",
    "\n",
    "response = requests.post(\n",
    "    f\"{API_URL}/synthesize\",\n",
    "    data={\n",
    "        \"text\": TEXT,\n",
    "        \"reference_text\": REFERENCE_TEXT,\n",
    "        \"pitch_shift\": PITCH_SHIFT,\n",
    "        \"f0_method\": F0_METHOD,\n",
    "        \"index_rate\": INDEX_RATE,\n",
    "        \"skip_rvc\": False,\n",
    "    },\n",
    "    files={\n",
    "        \"reference_audio\": (\"reference.wav\", ref_audio_data, \"audio/wav\")\n",
    "    },\n",
    "    timeout=120\n",
    ")\n",
    "\n",
    "total_time = time.time() - start_time\n",
    "\n",
    "if response.status_code == 200:\n",
    "    # Get timing from headers\n",
    "    tts_time = float(response.headers.get(\"X-TTS-Time\", 0))\n",
    "    rvc_time = float(response.headers.get(\"X-RVC-Time\", 0))\n",
    "    \n",
    "    # Save audio\n",
    "    output_path = \"TEMP/output/synthesized.wav\"\n",
    "    with open(output_path, \"wb\") as f:\n",
    "        f.write(response.content)\n",
    "    \n",
    "    # Get duration\n",
    "    audio, sr = sf.read(output_path)\n",
    "    duration = len(audio) / sr\n",
    "    \n",
    "    print(f\"\\nSuccess!\")\n",
    "    print(f\"  TTS time: {tts_time:.2f}s\")\n",
    "    print(f\"  RVC time: {rvc_time:.2f}s\")\n",
    "    print(f\"  Total time: {total_time:.2f}s\")\n",
    "    print(f\"  Audio duration: {duration:.2f}s\")\n",
    "    print(f\"  Saved to: {output_path}\")\n",
    "else:\n",
    "    print(f\"\\nError: {response.status_code}\")\n",
    "    print(response.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 6.2: Play output audio\n",
    "from IPython.display import Audio, display\n",
    "import os\n",
    "\n",
    "output_path = \"TEMP/output/synthesized.wav\"\n",
    "\n",
    "if os.path.exists(output_path):\n",
    "    print(\"Synthesized audio (TTS + RVC):\")\n",
    "    display(Audio(output_path))\n",
    "else:\n",
    "    print(\"No output file found. Run synthesis first.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 6.3: TTS only (skip RVC)\n",
    "import requests\n",
    "import time\n",
    "\n",
    "API_URL = \"http://localhost:8003\"\n",
    "\n",
    "TEXT = \"This is TTS only, without voice conversion.\"\n",
    "\n",
    "print(f\"Text: {TEXT}\")\n",
    "print(\"Running TTS only (skip_rvc=True)...\")\n",
    "\n",
    "with open(reference_audio_16k, \"rb\") as f:\n",
    "    ref_audio_data = f.read()\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "response = requests.post(\n",
    "    f\"{API_URL}/synthesize\",\n",
    "    data={\n",
    "        \"text\": TEXT,\n",
    "        \"reference_text\": \"\",\n",
    "        \"skip_rvc\": True,  # Skip RVC\n",
    "    },\n",
    "    files={\n",
    "        \"reference_audio\": (\"reference.wav\", ref_audio_data, \"audio/wav\")\n",
    "    },\n",
    "    timeout=60\n",
    ")\n",
    "\n",
    "if response.status_code == 200:\n",
    "    tts_time = float(response.headers.get(\"X-TTS-Time\", 0))\n",
    "    \n",
    "    output_path = \"TEMP/output/tts_only.wav\"\n",
    "    with open(output_path, \"wb\") as f:\n",
    "        f.write(response.content)\n",
    "    \n",
    "    print(f\"TTS time: {tts_time:.2f}s\")\n",
    "    print(f\"Saved to: {output_path}\")\n",
    "    \n",
    "    from IPython.display import Audio, display\n",
    "    display(Audio(output_path))\n",
    "else:\n",
    "    print(f\"Error: {response.status_code} - {response.text}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Section 7: Batch Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 7.1: Process multiple sentences\n",
    "import requests\n",
    "import time\n",
    "import re\n",
    "import soundfile as sf\n",
    "\n",
    "API_URL = \"http://localhost:8003\"\n",
    "\n",
    "LONG_TEXT = \"\"\"\n",
    "This is the first sentence of our test.\n",
    "The second sentence demonstrates the HTTP API approach.\n",
    "Third sentence continues the voice synthesis test.\n",
    "Fourth sentence shows the unified container working.\n",
    "Fifth and final sentence completes our batch test.\n",
    "\"\"\".strip()\n",
    "\n",
    "# Split into sentences\n",
    "sentences = [s.strip() for s in re.split(r'(?<=[.!?])\\s+', LONG_TEXT) if s.strip()]\n",
    "print(f\"Processing {len(sentences)} sentences...\\n\")\n",
    "\n",
    "# Load reference audio once\n",
    "with open(reference_audio_16k, \"rb\") as f:\n",
    "    ref_audio_data = f.read()\n",
    "\n",
    "total_start = time.time()\n",
    "results = []\n",
    "\n",
    "for i, sentence in enumerate(sentences):\n",
    "    print(f\"[{i+1}/{len(sentences)}] {sentence[:40]}...\")\n",
    "    \n",
    "    start = time.time()\n",
    "    response = requests.post(\n",
    "        f\"{API_URL}/synthesize\",\n",
    "        data={\n",
    "            \"text\": sentence,\n",
    "            \"reference_text\": \"\",\n",
    "            \"pitch_shift\": PITCH_SHIFT,\n",
    "            \"f0_method\": F0_METHOD,\n",
    "            \"index_rate\": INDEX_RATE,\n",
    "        },\n",
    "        files={\n",
    "            \"reference_audio\": (\"reference.wav\", ref_audio_data, \"audio/wav\")\n",
    "        },\n",
    "        timeout=120\n",
    "    )\n",
    "    elapsed = time.time() - start\n",
    "    \n",
    "    if response.status_code == 200:\n",
    "        tts_time = float(response.headers.get(\"X-TTS-Time\", 0))\n",
    "        rvc_time = float(response.headers.get(\"X-RVC-Time\", 0))\n",
    "        \n",
    "        output_path = f\"TEMP/output/sentence_{i}.wav\"\n",
    "        with open(output_path, \"wb\") as f:\n",
    "            f.write(response.content)\n",
    "        \n",
    "        audio, sr = sf.read(output_path)\n",
    "        results.append(audio)\n",
    "        \n",
    "        print(f\"    TTS: {tts_time:.2f}s, RVC: {rvc_time:.2f}s, Total: {elapsed:.2f}s\")\n",
    "    else:\n",
    "        print(f\"    Error: {response.status_code}\")\n",
    "\n",
    "total_time = time.time() - total_start\n",
    "print(f\"\\nTotal: {total_time:.2f}s for {len(sentences)} sentences ({total_time/len(sentences):.2f}s/sentence)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 7.2: Concatenate and play all sentences\n",
    "import numpy as np\n",
    "import soundfile as sf\n",
    "from IPython.display import Audio, display\n",
    "\n",
    "if results:\n",
    "    # Add small silence between sentences\n",
    "    silence = np.zeros(int(16000 * 0.3))  # 300ms\n",
    "    \n",
    "    combined = []\n",
    "    for i, audio in enumerate(results):\n",
    "        combined.append(audio)\n",
    "        if i < len(results) - 1:\n",
    "            combined.append(silence)\n",
    "    \n",
    "    full_audio = np.concatenate(combined)\n",
    "    output_path = \"TEMP/output/combined.wav\"\n",
    "    sf.write(output_path, full_audio, 16000)\n",
    "    \n",
    "    print(f\"Combined audio: {len(full_audio)/16000:.2f}s\")\n",
    "    display(Audio(output_path))\n",
    "else:\n",
    "    print(\"No results to combine.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Section 8: Advanced Options"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 8.1: RVC only (convert existing audio)\n",
    "import requests\n",
    "import soundfile as sf\n",
    "from IPython.display import Audio, display\n",
    "\n",
    "API_URL = \"http://localhost:8003\"\n",
    "\n",
    "# Use TTS output as input for RVC-only conversion\n",
    "input_audio = \"TEMP/output/tts_only.wav\"\n",
    "\n",
    "if os.path.exists(input_audio):\n",
    "    print(f\"Converting: {input_audio}\")\n",
    "    \n",
    "    with open(input_audio, \"rb\") as f:\n",
    "        audio_data = f.read()\n",
    "    \n",
    "    response = requests.post(\n",
    "        f\"{API_URL}/rvc\",\n",
    "        data={\n",
    "            \"pitch_shift\": 0,\n",
    "            \"f0_method\": \"rmvpe\",\n",
    "            \"index_rate\": 1.0,\n",
    "        },\n",
    "        files={\n",
    "            \"audio\": (\"input.wav\", audio_data, \"audio/wav\")\n",
    "        },\n",
    "        timeout=60\n",
    "    )\n",
    "    \n",
    "    if response.status_code == 200:\n",
    "        output_path = \"TEMP/output/rvc_only.wav\"\n",
    "        with open(output_path, \"wb\") as f:\n",
    "            f.write(response.content)\n",
    "        \n",
    "        rvc_time = float(response.headers.get(\"X-RVC-Time\", 0))\n",
    "        print(f\"RVC time: {rvc_time:.2f}s\")\n",
    "        print(f\"Saved to: {output_path}\")\n",
    "        \n",
    "        print(\"\\nOriginal:\")\n",
    "        display(Audio(input_audio))\n",
    "        print(\"\\nRVC converted:\")\n",
    "        display(Audio(output_path))\n",
    "    else:\n",
    "        print(f\"Error: {response.status_code} - {response.text}\")\n",
    "else:\n",
    "    print(f\"Input file not found: {input_audio}\")\n",
    "    print(\"Run Cell 6.3 (TTS only) first.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 8.2: Test different pitch shifts\n",
    "import requests\n",
    "import soundfile as sf\n",
    "from IPython.display import Audio, display\n",
    "\n",
    "API_URL = \"http://localhost:8003\"\n",
    "\n",
    "TEXT = \"Testing different pitch shifts.\"\n",
    "PITCH_SHIFTS = [-6, 0, 6, 12]\n",
    "\n",
    "with open(reference_audio_16k, \"rb\") as f:\n",
    "    ref_audio_data = f.read()\n",
    "\n",
    "for pitch in PITCH_SHIFTS:\n",
    "    print(f\"\\nPitch shift: {pitch:+d} semitones\")\n",
    "    \n",
    "    response = requests.post(\n",
    "        f\"{API_URL}/synthesize\",\n",
    "        data={\n",
    "            \"text\": TEXT,\n",
    "            \"reference_text\": \"\",\n",
    "            \"pitch_shift\": pitch,\n",
    "            \"f0_method\": \"rmvpe\",\n",
    "            \"index_rate\": 1.0,\n",
    "        },\n",
    "        files={\n",
    "            \"reference_audio\": (\"reference.wav\", ref_audio_data, \"audio/wav\")\n",
    "        },\n",
    "        timeout=60\n",
    "    )\n",
    "    \n",
    "    if response.status_code == 200:\n",
    "        output_path = f\"TEMP/output/pitch_{pitch:+d}.wav\"\n",
    "        with open(output_path, \"wb\") as f:\n",
    "            f.write(response.content)\n",
    "        display(Audio(output_path))\n",
    "    else:\n",
    "        print(f\"  Error: {response.status_code}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Section 9: Shutdown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 9.1: Shutdown services\n",
    "import time\n",
    "\n",
    "print(\"Shutting down services...\")\n",
    "\n",
    "# Kill processes inside container\n",
    "!pkill -f tritonserver\n",
    "!pkill -f \"uvicorn.*voice_api\"\n",
    "!pkill -f \"udocker.*voice_server\"\n",
    "\n",
    "time.sleep(3)\n",
    "\n",
    "print(\"\\nGPU status after shutdown:\")\n",
    "!nvidia-smi"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
