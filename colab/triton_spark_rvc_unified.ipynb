{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "# Triton Spark TTS + RVC Voice Conversion (Unified Container)\n\nThis notebook runs the full pipeline with **both services inside a single udocker container**:\n1. **Triton Spark TTS** - Text-to-Speech (internal gRPC, port 8001)\n2. **RVC Voice Conversion** - Voice cloning (inline processing)\n3. **Voice HTTP API** - Unified endpoint (port 8003)\n\n## Architecture\n```\n‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\n‚îÇ  udocker Container                                      ‚îÇ\n‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê ‚îÇ\n‚îÇ  ‚îÇ Triton Server   ‚îÇ‚óÑ‚îÄ‚îÄ‚îÄ‚îÇ Voice HTTP API (:8003)      ‚îÇ ‚îÇ\n‚îÇ  ‚îÇ (Spark TTS)     ‚îÇ    ‚îÇ - FastAPI wrapper           ‚îÇ ‚îÇ\n‚îÇ  ‚îÇ :8001 gRPC      ‚îÇ    ‚îÇ - TTS + RVC combined        ‚îÇ ‚îÇ\n‚îÇ  ‚îÇ (internal)      ‚îÇ    ‚îÇ - N parallel RVC workers    ‚îÇ ‚îÇ\n‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò ‚îÇ\n‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n                                   ‚ñ≤\n                                   ‚îÇ HTTP\n                                   ‚ñº\n                            Host Python\n                         (simple requests)\n```\n\n## Port Allocation\n- `8000` - Triton HTTP (internal)\n- `8001` - Triton gRPC (internal)\n- `8002` - Triton Metrics (internal)\n- `8003` - Voice HTTP API (external)\n\n## API Endpoints\n- `POST /synthesize/sse` - SSE streaming for web clients (JSON events with base64 audio)\n- `POST /synthesize/stream` - Streaming multipart audio response\n- `POST /tts` - TTS only\n- `POST /rvc` - RVC only\n- `GET /health` - Health check\n- `GET /status` - Detailed status\n\n## Benefits\n- Simple HTTP interface (no gRPC complexity on host)\n- Both services share CUDA context inside container\n- Single container to manage\n- No GPU memory fragmentation\n\n## Requirements\n- Google Colab with GPU runtime (T4 minimum, A100 recommended)\n- ~12GB disk space for models and dependencies"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Section 1: Setup Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 1.1: Initialize udocker\n",
    "import os\n",
    "\n",
    "def udocker_init():\n",
    "    if not os.path.exists(\"/home/user\"):\n",
    "        !pip install udocker > /dev/null\n",
    "        !udocker --allow-root install > /dev/null\n",
    "        !useradd -m user > /dev/null\n",
    "    print('udocker initialized')\n",
    "\n",
    "udocker_init()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 1.2: Clone repository\n",
    "!git clone https://github.com/VSlobolinskyi/triton-spark-server.git\n",
    "%cd triton-spark-server"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 1.3: GPU Configuration for udocker\n",
    "import subprocess\n",
    "\n",
    "def detect_gpu_paths():\n",
    "    paths = {}\n",
    "    paths['nvidia_smi'] = subprocess.getoutput('which nvidia-smi')\n",
    "    paths['cuda_dir'] = subprocess.getoutput(\"find /usr -path '*/cuda*' -type d -maxdepth 3 | grep -v 'targets' | head -1\")\n",
    "    paths['nvidia_lib_dir'] = subprocess.getoutput(\"find /usr -name 'libcuda.so*' -o -name 'libnvidia-ml.so*' | grep -v 'stubs' | xargs dirname | sort -u | head -1\")\n",
    "    paths['ld_library_path'] = f\"{paths['nvidia_lib_dir']}:{paths['cuda_dir']}/lib64:{paths['cuda_dir']}/compat\"\n",
    "\n",
    "    basic_devices = ['/dev/nvidia0', '/dev/nvidiactl', '/dev/nvidia-uvm']\n",
    "\n",
    "    volumes = [\n",
    "        f\"--volume={paths['nvidia_smi']}:{paths['nvidia_smi']}\",\n",
    "        f\"--volume={paths['nvidia_lib_dir']}:{paths['nvidia_lib_dir']}\",\n",
    "        f\"--volume={paths['cuda_dir']}:{paths['cuda_dir']}\"\n",
    "    ]\n",
    "\n",
    "    for device in basic_devices:\n",
    "        if os.path.exists(device):\n",
    "            volumes.append(f\"--volume={device}:{device}\")\n",
    "\n",
    "    env_vars = [\n",
    "        f\"--env=LD_LIBRARY_PATH={paths['ld_library_path']}:/usr/local/tensorrt/targets/x86_64-linux-gnu/lib:$LD_LIBRARY_PATH\",\n",
    "        f\"--env=PATH=/opt/tritonserver/bin:{paths['cuda_dir']}/bin:/usr/bin:$PATH\",\n",
    "        \"--env=NVIDIA_VISIBLE_DEVICES=all\",\n",
    "        \"--env=NVIDIA_DRIVER_CAPABILITIES=compute,utility\"\n",
    "    ]\n",
    "\n",
    "    return {\n",
    "        'paths': paths,\n",
    "        'volumes': volumes,\n",
    "        'env_vars': env_vars,\n",
    "        'all_options': ' '.join(volumes + env_vars)\n",
    "    }\n",
    "\n",
    "gpu_config = detect_gpu_paths()\n",
    "print(\"GPU configuration ready\")\n",
    "for k, v in gpu_config['paths'].items():\n",
    "    print(f\"  {k}: {v}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Section 2: Setup Container with TTS + RVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 2.1: Pull Triton Server image\n",
    "!udocker --allow-root pull nvcr.io/nvidia/tritonserver:25.02-trtllm-python-py3\n",
    "!udocker --allow-root create --name=voice_server nvcr.io/nvidia/tritonserver:25.02-trtllm-python-py3\n",
    "!udocker --allow-root setup --nvidia voice_server"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 2.2: Install TTS dependencies (torchaudio, etc.)\n",
    "import os\n",
    "pwd = os.getcwd()\n",
    "\n",
    "tts_deps_cmd = f'''udocker --allow-root run \\\n",
    "    --hostauth --hostenv \\\n",
    "    {gpu_config['all_options']} \\\n",
    "    --volume={pwd}:/workspace \\\n",
    "    voice_server \\\n",
    "    /bin/bash -c \"apt-get update && apt-get install -y cmake curl ffmpeg && \\\n",
    "git clone https://github.com/pytorch/audio.git && cd audio && git checkout c670ad8 && USE_FFMPEG=0 PATH=/usr/local/cuda/bin:\\$PATH python3 setup.py develop && \\\n",
    "pip install einx==0.3.0 omegaconf==2.3.0 soundfile==0.12.1 soxr==0.5.0.post1 tritonclient librosa 'huggingface-hub>=0.24.0,<1.0'\"\n",
    "'''\n",
    "\n",
    "!{tts_deps_cmd}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 2.3: Install RVC + HTTP API dependencies inside container\n",
    "import os\n",
    "pwd = os.getcwd()\n",
    "\n",
    "rvc_deps_cmd = f'''udocker --allow-root run \\\n",
    "    --hostauth --hostenv \\\n",
    "    {gpu_config['all_options']} \\\n",
    "    --volume={pwd}:/workspace \\\n",
    "    voice_server \\\n",
    "    /bin/bash -c \"pip install --no-cache-dir \\\n",
    "        faiss-cpu>=1.7.0 \\\n",
    "        pyworld==0.3.2 \\\n",
    "        praat-parselmouth>=0.4.2 \\\n",
    "        torchcrepe==0.0.23 \\\n",
    "        ffmpeg-python>=0.2.0 \\\n",
    "        av>=9.0.0 \\\n",
    "        onnxruntime-gpu>=1.13.0 \\\n",
    "        numba>=0.56.0 \\\n",
    "        joblib>=1.1.0 \\\n",
    "        fastapi>=0.100.0 \\\n",
    "        uvicorn>=0.21.1 \\\n",
    "        python-multipart>=0.0.6 \\\n",
    "        sse-starlette>=1.6.0 && \\\n",
    "    pip install --no-cache-dir git+https://github.com/One-sixth/fairseq.git\"\n",
    "'''\n",
    "\n",
    "print(\"Installing RVC + HTTP API dependencies in container...\")\n",
    "!{rvc_deps_cmd}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 2.4: Build TensorRT-LLM engine for Spark TTS\n",
    "import os\n",
    "pwd = os.getcwd()\n",
    "\n",
    "build_cmd = f'''udocker --allow-root run \\\n",
    "    --hostauth --hostenv \\\n",
    "    {gpu_config['all_options']} \\\n",
    "    --env=PYTHONPATH=/workspace \\\n",
    "    --volume={pwd}:/workspace \\\n",
    "    voice_server \\\n",
    "    /bin/bash -c \"cd /workspace/triton && bash run.sh 0 2 offline\"'''\n",
    "\n",
    "print(\"Building TensorRT engine for Spark TTS...\")\n",
    "!{build_cmd}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Section 3: Download Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 3.1: Download RVC assets (HuBERT, RMVPE) - run inside container\n",
    "import os\n",
    "pwd = os.getcwd()\n",
    "\n",
    "assets_cmd = f'''udocker --allow-root run \\\n",
    "    --hostauth --hostenv \\\n",
    "    {gpu_config['all_options']} \\\n",
    "    --env=PYTHONPATH=/workspace \\\n",
    "    --volume={pwd}:/workspace \\\n",
    "    voice_server \\\n",
    "    /bin/bash -c \"cd /workspace && python3 tools/download_all_assets.py --rvc-only\"'''\n",
    "\n",
    "print(\"Downloading RVC assets...\")\n",
    "!{assets_cmd}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 3.2: Download RVC voice model\n",
    "import os\n",
    "pwd = os.getcwd()\n",
    "\n",
    "RVC_MODEL_URL = \"https://huggingface.co/Juneuarie/SilverWolfEN/resolve/main/SilverWolf.zip?download=true\"\n",
    "\n",
    "model_cmd = f'''udocker --allow-root run \\\n",
    "    --hostauth --hostenv \\\n",
    "    {gpu_config['all_options']} \\\n",
    "    --env=PYTHONPATH=/workspace \\\n",
    "    --volume={pwd}:/workspace \\\n",
    "    voice_server \\\n",
    "    /bin/bash -c \"cd /workspace && python3 tools/download_all_assets.py --rvc-model '{RVC_MODEL_URL}'\"'''\n",
    "\n",
    "print(\"Downloading RVC voice model...\")\n",
    "!{model_cmd}\n",
    "\n",
    "# List downloaded models and index files\n",
    "print(\"\\n=== Downloaded Files ===\")\n",
    "print(\"\\nVoice models (.pth):\")\n",
    "!ls -la assets/weights/*.pth 2>/dev/null || echo \"  No .pth files found in assets/weights/\"\n",
    "\n",
    "print(\"\\nIndex files (.index) - REQUIRED for voice quality:\")\n",
    "!ls -la logs/*.index 2>/dev/null || echo \"  WARNING: No .index files found in logs/\"\n",
    "!ls -la assets/*.index 2>/dev/null || echo \"\"\n",
    "\n",
    "# Check if index exists\n",
    "import glob\n",
    "index_files = glob.glob(\"logs/*.index\") + glob.glob(\"assets/*.index\")\n",
    "if not index_files:\n",
    "    print(\"\\n*** WARNING: No index file found! Voice quality enhancement will be disabled. ***\")\n",
    "    print(\"The RVC model zip should contain a .index file for best results.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Section 4: Start Voice Services"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 4.1: Start Voice HTTP API (Triton + RVC inside container)\n",
    "import subprocess\n",
    "import time\n",
    "import os\n",
    "\n",
    "pwd = os.getcwd()\n",
    "\n",
    "# Configuration\n",
    "RVC_MODEL = \"SilverWolf_e300_s6600.pth\"\n",
    "RVC_WORKERS = 2  # 2 for L4, up to 4 for A100\n",
    "API_PORT = 8003  # Triton uses 8000-8002, so we use 8003\n",
    "\n",
    "# Start services via startup script\n",
    "# NOTE: RVC requires these environment variables for model loading:\n",
    "#   - rmvpe_root: Path to rmvpe.pt for pitch extraction\n",
    "#   - hubert_base_path: Path to hubert_base.pt for feature extraction\n",
    "#   - weight_root: Path to RVC voice model weights\n",
    "#   - index_root: Path to .index files for voice quality enhancement\n",
    "server_cmd = f'''udocker --allow-root run \\\n",
    "    --hostauth --hostenv \\\n",
    "    {gpu_config['all_options']} \\\n",
    "    --env=PYTHONPATH=/workspace \\\n",
    "    --env=RVC_MODEL={RVC_MODEL} \\\n",
    "    --env=RVC_WORKERS={RVC_WORKERS} \\\n",
    "    --env=API_PORT={API_PORT} \\\n",
    "    --env=rmvpe_root=/workspace/assets/rmvpe \\\n",
    "    --env=hubert_base_path=/workspace/assets/hubert/hubert_base.pt \\\n",
    "    --env=weight_root=/workspace/assets/weights \\\n",
    "    --env=index_root=/workspace/logs \\\n",
    "    --volume={pwd}:/workspace \\\n",
    "    voice_server \\\n",
    "    /bin/bash /workspace/scripts/start_services.sh'''\n",
    "\n",
    "# Run in background\n",
    "process = subprocess.Popen(\n",
    "    f\"nohup {server_cmd} > services_log.txt 2>&1 &\",\n",
    "    shell=True\n",
    ")\n",
    "\n",
    "print(\"Starting voice services...\")\n",
    "print(f\"  Voice HTTP API: http://localhost:{API_PORT}\")\n",
    "print(f\"  RVC Workers: {RVC_WORKERS}\")\n",
    "print(f\"  RVC Model: {RVC_MODEL}\")\n",
    "print(\"\\nWaiting 150 seconds for services to initialize...\")\n",
    "time.sleep(150)\n",
    "\n",
    "print(\"\\nService logs:\")\n",
    "!tail -50 services_log.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 4.2: Install host Python dependencies (just requests + audio)\n",
    "!pip install -q requests soundfile numpy\n",
    "\n",
    "# Run this cell if you want to access the API from outside Colab (e.g., from your Angular frontend)\n",
    "!pip install -q pyngrok\n",
    "\n",
    "print(\"Host dependencies installed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 4.3: Test connection to Voice HTTP API\n",
    "import requests\n",
    "\n",
    "API_URL = \"http://localhost:8003\"\n",
    "\n",
    "print(\"Testing Voice HTTP API connection...\")\n",
    "\n",
    "# Health check\n",
    "try:\n",
    "    response = requests.get(f\"{API_URL}/health\", timeout=10)\n",
    "    if response.status_code == 200:\n",
    "        health = response.json()\n",
    "        print(f\"  Health: {health['status']}\")\n",
    "        print(f\"  Triton ready: {health.get('triton_ready', 'N/A')}\")\n",
    "        print(f\"  RVC ready: {health.get('rvc_ready', 'N/A')}\")\n",
    "    else:\n",
    "        print(f\"  Health check failed: {response.status_code}\")\n",
    "except requests.exceptions.RequestException as e:\n",
    "    print(f\"  Connection error: {e}\")\n",
    "\n",
    "# Detailed status\n",
    "print(\"\\nDetailed status:\")\n",
    "try:\n",
    "    response = requests.get(f\"{API_URL}/status\", timeout=10)\n",
    "    if response.status_code == 200:\n",
    "        status = response.json()\n",
    "        print(f\"  RVC Model: {status.get('rvc_model', 'N/A')}\")\n",
    "        print(f\"  RVC Workers: {status.get('rvc_workers', 'N/A')}\")\n",
    "        print(f\"  Triton address: {status.get('triton_addr', 'N/A')}:{status.get('triton_port', 'N/A')}\")\n",
    "except requests.exceptions.RequestException as e:\n",
    "    print(f\"  Status check failed: {e}\")\n",
    "\n",
    "print(\"\\nGPU memory usage:\")\n",
    "!nvidia-smi --query-gpu=memory.used,memory.total --format=csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Cell 4.4: Expose API externally via ngrok (OPTIONAL)\n\nfrom pyngrok import ngrok\nimport os\n\n# Set your authtoken (get it from https://dashboard.ngrok.com/get-started/your-authtoken)\nngrok.set_auth_token(\"YOUR_AUTHTOKEN_HERE\")\n\nAPI_PORT = 8003\n\n# Create tunnel\ntunnel = ngrok.connect(API_PORT, \"http\")\npublic_url = tunnel.public_url  # Extract just the URL string\n\nprint(\"=\" * 60)\nprint(\"üåê API exposed externally!\")\nprint(f\"   Public URL: {public_url}\")\nprint(\"=\" * 60)\nprint(f'\\nRun this in browser console:')\nprint(f'localStorage.setItem(\"apiUrl\", \"{public_url}\")')\nos.environ['PUBLIC_API_URL'] = public_url"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Section 5: Upload Reference Audio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 5.1: Upload reference audio\n",
    "import os\n",
    "import soundfile as sf\n",
    "from google.colab import files\n",
    "\n",
    "!mkdir -p references TEMP/output\n",
    "\n",
    "print(\"Please upload a reference audio file (.wav format):\")\n",
    "uploaded = files.upload()\n",
    "\n",
    "reference_audio = list(uploaded.keys())[0]\n",
    "references_path = os.path.join(\"references\", reference_audio)\n",
    "\n",
    "with open(references_path, \"wb\") as f:\n",
    "    f.write(uploaded[reference_audio])\n",
    "\n",
    "audio, sr = sf.read(references_path)\n",
    "print(f\"Saved: {references_path} ({len(audio)/sr:.2f}s @ {sr}Hz)\")\n",
    "\n",
    "# Resample to 16kHz if needed\n",
    "if sr != 16000:\n",
    "    base_name = os.path.splitext(reference_audio)[0]\n",
    "    reference_audio_16k = os.path.join(\"references\", f\"{base_name}_16k.wav\")\n",
    "    !ffmpeg -y -i \"{references_path}\" -ar 16000 \"{reference_audio_16k}\" -loglevel error\n",
    "    print(f\"Resampled to 16kHz: {reference_audio_16k}\")\n",
    "else:\n",
    "    reference_audio_16k = references_path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Section 6: Run Voice Synthesis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Cell 6.1: Synthesize with SSE endpoint (full pipeline)\nimport requests\nimport time\nimport json\nimport io\nimport base64\n\nAPI_URL = \"http://localhost:8003\"\n\n# Configuration\nTEXT = \"Hello! This is a test of the unified voice synthesis pipeline. Both TTS and RVC are running inside a single container, exposed via a simple HTTP API.\"\nREFERENCE_TEXT = \"\"\n\n# RVC Parameters for quality enhancement\nPITCH_SHIFT = 0           # Pitch shift in semitones (-12 to +12)\nF0_METHOD = \"rmvpe\"       # Pitch extraction: rmvpe (best), pm, harvest, crepe\nINDEX_RATE = 1.0          # Voice similarity (0.0-1.0), 1.0 = maximum quality\nFILTER_RADIUS = 3         # Pitch smoothing (0-7), higher = smoother\nRMS_MIX_RATE = 0.0        # Volume envelope: 0.0 = use TTS envelope (recommended)\nPROTECT = 0.33            # Consonant protection (0.0-0.5), lower = more protection\n\nprint(f\"Text: {TEXT[:60]}...\")\nprint(f\"Reference: {reference_audio_16k}\")\nprint(f\"Settings: pitch={PITCH_SHIFT}, f0={F0_METHOD}, index_rate={INDEX_RATE}\")\nprint(f\"Quality: filter_radius={FILTER_RADIUS}, rms_mix={RMS_MIX_RATE}, protect={PROTECT}\")\n\n# Prepare request\nwith open(reference_audio_16k, \"rb\") as f:\n    ref_audio_data = f.read()\n\n# Call SSE synthesis endpoint\nprint(\"\\nRunning TTS + RVC synthesis via SSE...\")\nstart_time = time.time()\n\nresponse = requests.post(\n    f\"{API_URL}/synthesize/sse\",\n    data={\n        \"text\": TEXT,\n        \"reference_text\": REFERENCE_TEXT,\n        \"pitch_shift\": PITCH_SHIFT,\n        \"f0_method\": F0_METHOD,\n        \"index_rate\": INDEX_RATE,\n        \"filter_radius\": FILTER_RADIUS,\n        \"rms_mix_rate\": RMS_MIX_RATE,\n        \"protect\": PROTECT,\n        \"skip_rvc\": False,\n    },\n    files={\n        \"reference_audio\": (\"reference.wav\", ref_audio_data, \"audio/wav\")\n    },\n    stream=True,\n    timeout=120\n)\n\n# Collect audio chunks\naudio_chunks = []\ntotal_tts_time = 0.0\ntotal_rvc_time = 0.0\n\nfor line in response.iter_lines():\n    if line:\n        line_str = line.decode('utf-8')\n        if line_str.startswith('data:'):\n            data = json.loads(line_str[5:].strip())\n            if data.get('type') == 'chunk':\n                audio_chunks.append(base64.b64decode(data['data']))\n                total_tts_time += data.get('tts_time', 0)\n                total_rvc_time += data.get('rvc_time', 0)\n                print(f\"  Chunk {data['index']}: TTS {data.get('tts_time', 0):.2f}s, RVC {data.get('rvc_time', 0):.2f}s\")\n\ntotal_time = time.time() - start_time\n\nif audio_chunks:\n    # Combine chunks and save\n    # Each chunk is a complete WAV file, we need to extract raw audio and combine\n    import numpy as np\n    \n    combined_audio = []\n    sample_rate = None\n    \n    for chunk_bytes in audio_chunks:\n        audio, sr = sf.read(io.BytesIO(chunk_bytes))\n        combined_audio.append(audio)\n        sample_rate = sr\n    \n    final_audio = np.concatenate(combined_audio)\n    output_path = \"TEMP/output/synthesized.wav\"\n    sf.write(output_path, final_audio, sample_rate)\n    \n    duration = len(final_audio) / sample_rate\n    \n    print(f\"\\nSuccess!\")\n    print(f\"  Total TTS time: {total_tts_time:.2f}s\")\n    print(f\"  Total RVC time: {total_rvc_time:.2f}s\")\n    print(f\"  Total time: {total_time:.2f}s\")\n    print(f\"  Audio duration: {duration:.2f}s\")\n    print(f\"  Sample rate: {sample_rate}Hz\")\n    print(f\"  Saved to: {output_path}\")\nelse:\n    print(f\"\\nError: No audio chunks received\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 6.2: Play output audio\n",
    "from IPython.display import Audio, display\n",
    "import os\n",
    "\n",
    "output_path = \"TEMP/output/synthesized.wav\"\n",
    "\n",
    "if os.path.exists(output_path):\n",
    "    print(\"Synthesized audio (TTS + RVC):\")\n",
    "    display(Audio(output_path))\n",
    "else:\n",
    "    print(\"No output file found. Run synthesis first.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Cell 6.3: TTS only (using /tts endpoint)\nimport requests\nimport time\n\nAPI_URL = \"http://localhost:8003\"\n\nTEXT = \"This is TTS only, without voice conversion.\"\n\nprint(f\"Text: {TEXT}\")\nprint(\"Running TTS only via /tts endpoint...\")\n\nwith open(reference_audio_16k, \"rb\") as f:\n    ref_audio_data = f.read()\n\nstart_time = time.time()\n\nresponse = requests.post(\n    f\"{API_URL}/tts\",\n    data={\n        \"text\": TEXT,\n        \"reference_text\": \"\",\n    },\n    files={\n        \"reference_audio\": (\"reference.wav\", ref_audio_data, \"audio/wav\")\n    },\n    timeout=60\n)\n\nif response.status_code == 200:\n    tts_time = float(response.headers.get(\"X-Processing-Time\", 0))\n    \n    output_path = \"TEMP/output/tts_only.wav\"\n    with open(output_path, \"wb\") as f:\n        f.write(response.content)\n    \n    print(f\"TTS time: {tts_time:.2f}s\")\n    print(f\"Saved to: {output_path}\")\n    \n    from IPython.display import Audio, display\n    display(Audio(output_path))\nelse:\n    print(f\"Error: {response.status_code} - {response.text}\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Section 7: Batch Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Cell 7.1: Process multiple sentences via SSE\nimport requests\nimport time\nimport json\nimport base64\nimport io\nimport soundfile as sf\nimport numpy as np\n\nAPI_URL = \"http://localhost:8003\"\n\nLONG_TEXT = \"\"\"\nThis is the first sentence of our test.\nThe second sentence demonstrates the SSE streaming approach.\nThird sentence continues the voice synthesis test.\nFourth sentence shows the unified container working.\nFifth and final sentence completes our batch test.\n\"\"\".strip()\n\nprint(f\"Processing text via SSE endpoint...\\n\")\nprint(f\"Text: {LONG_TEXT[:80]}...\")\n\n# Load reference audio once\nwith open(reference_audio_16k, \"rb\") as f:\n    ref_audio_data = f.read()\n\ntotal_start = time.time()\n\n# Call SSE endpoint with full text (it will split into sentences internally)\nresponse = requests.post(\n    f\"{API_URL}/synthesize/sse\",\n    data={\n        \"text\": LONG_TEXT,\n        \"reference_text\": \"\",\n        \"pitch_shift\": PITCH_SHIFT,\n        \"f0_method\": F0_METHOD,\n        \"index_rate\": INDEX_RATE,\n        \"filter_radius\": FILTER_RADIUS,\n        \"rms_mix_rate\": RMS_MIX_RATE,\n        \"protect\": PROTECT,\n    },\n    files={\n        \"reference_audio\": (\"reference.wav\", ref_audio_data, \"audio/wav\")\n    },\n    stream=True,\n    timeout=300\n)\n\nresults = []\ntotal_tts = 0.0\ntotal_rvc = 0.0\n\nfor line in response.iter_lines():\n    if line:\n        line_str = line.decode('utf-8')\n        if line_str.startswith('data:'):\n            data = json.loads(line_str[5:].strip())\n            if data.get('type') == 'start':\n                print(f\"Stream started: {data.get('total_chunks')} chunks expected\")\n            elif data.get('type') == 'chunk':\n                audio_bytes = base64.b64decode(data['data'])\n                audio, sr = sf.read(io.BytesIO(audio_bytes))\n                results.append(audio)\n                \n                tts_time = data.get('tts_time', 0)\n                rvc_time = data.get('rvc_time', 0)\n                total_tts += tts_time\n                total_rvc += rvc_time\n                \n                text_preview = data.get('text', '')[:40]\n                print(f\"  [{data['index']+1}] {text_preview}... TTS: {tts_time:.2f}s, RVC: {rvc_time:.2f}s\")\n            elif data.get('type') == 'end':\n                print(\"Stream complete\")\n\ntotal_time = time.time() - total_start\nprint(f\"\\nTotal: {total_time:.2f}s for {len(results)} sentences ({total_time/max(len(results),1):.2f}s/sentence)\")\nprint(f\"  TTS total: {total_tts:.2f}s\")\nprint(f\"  RVC total: {total_rvc:.2f}s\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 7.2: Concatenate and play all sentences\n",
    "import numpy as np\n",
    "import soundfile as sf\n",
    "from IPython.display import Audio, display\n",
    "\n",
    "if results:\n",
    "    # Get sample rate from first result file\n",
    "    _, sr = sf.read(\"TEMP/output/sentence_0.wav\")\n",
    "    \n",
    "    # Add small silence between sentences (at correct sample rate)\n",
    "    silence = np.zeros(int(sr * 0.3))  # 300ms\n",
    "    \n",
    "    combined = []\n",
    "    for i, audio in enumerate(results):\n",
    "        combined.append(audio)\n",
    "        if i < len(results) - 1:\n",
    "            combined.append(silence)\n",
    "    \n",
    "    full_audio = np.concatenate(combined)\n",
    "    output_path = \"TEMP/output/combined.wav\"\n",
    "    sf.write(output_path, full_audio, sr)\n",
    "    \n",
    "    print(f\"Combined audio: {len(full_audio)/sr:.2f}s @ {sr}Hz\")\n",
    "    display(Audio(output_path))\n",
    "else:\n",
    "    print(\"No results to combine.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Section 8: Advanced Options"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 8.1: RVC only (convert existing audio)\n",
    "import requests\n",
    "import soundfile as sf\n",
    "from IPython.display import Audio, display\n",
    "\n",
    "API_URL = \"http://localhost:8003\"\n",
    "\n",
    "# Use TTS output as input for RVC-only conversion\n",
    "input_audio = \"TEMP/output/tts_only.wav\"\n",
    "\n",
    "if os.path.exists(input_audio):\n",
    "    print(f\"Converting: {input_audio}\")\n",
    "    \n",
    "    with open(input_audio, \"rb\") as f:\n",
    "        audio_data = f.read()\n",
    "    \n",
    "    response = requests.post(\n",
    "        f\"{API_URL}/rvc\",\n",
    "        data={\n",
    "            \"pitch_shift\": PITCH_SHIFT,\n",
    "            \"f0_method\": F0_METHOD,\n",
    "            \"index_rate\": INDEX_RATE,\n",
    "            \"filter_radius\": FILTER_RADIUS,\n",
    "            \"rms_mix_rate\": RMS_MIX_RATE,\n",
    "            \"protect\": PROTECT,\n",
    "        },\n",
    "        files={\n",
    "            \"audio\": (\"input.wav\", audio_data, \"audio/wav\")\n",
    "        },\n",
    "        timeout=60\n",
    "    )\n",
    "    \n",
    "    if response.status_code == 200:\n",
    "        output_path = \"TEMP/output/rvc_only.wav\"\n",
    "        with open(output_path, \"wb\") as f:\n",
    "            f.write(response.content)\n",
    "        \n",
    "        rvc_time = float(response.headers.get(\"X-RVC-Time\", 0))\n",
    "        print(f\"RVC time: {rvc_time:.2f}s\")\n",
    "        print(f\"Saved to: {output_path}\")\n",
    "        \n",
    "        print(\"\\nOriginal:\")\n",
    "        display(Audio(input_audio))\n",
    "        print(\"\\nRVC converted:\")\n",
    "        display(Audio(output_path))\n",
    "    else:\n",
    "        print(f\"Error: {response.status_code} - {response.text}\")\n",
    "else:\n",
    "    print(f\"Input file not found: {input_audio}\")\n",
    "    print(\"Run Cell 6.3 (TTS only) first.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Cell 8.2: Benchmark - SSE Streaming Endpoint (matches frontend usage)\nimport requests\nimport time\nimport json\nimport soundfile as sf\nfrom IPython.display import Audio, display\n\nAPI_URL = \"http://localhost:8003\"\n\n# Test texts of varying lengths\nTEST_TEXTS = [\n    \"Short test.\",\n    \"This is a medium length sentence for testing the voice synthesis pipeline.\",\n    \"This is a longer test with multiple sentences. It should be split into chunks. Each chunk goes through TTS and RVC processing. The streaming endpoint sends each chunk as it's ready.\",\n]\n\nprint(\"=\" * 60)\nprint(\"SSE STREAMING BENCHMARK\")\nprint(\"=\" * 60)\n\n# Load reference audio\nwith open(reference_audio_16k, \"rb\") as f:\n    ref_audio_data = f.read()\n\nbenchmark_results = []\n\nfor i, text in enumerate(TEST_TEXTS):\n    print(f\"\\n--- Test {i+1}: {len(text)} chars, ~{len(text.split())} words ---\")\n    print(f\"Text: {text[:50]}{'...' if len(text) > 50 else ''}\")\n    \n    start_time = time.time()\n    \n    # Call SSE endpoint\n    response = requests.post(\n        f\"{API_URL}/synthesize/sse\",\n        data={\n            \"text\": text,\n            \"reference_text\": \"\",\n            \"pitch_shift\": 0,\n            \"f0_method\": \"rmvpe\",\n            \"index_rate\": 1.0,\n        },\n        files={\n            \"reference_audio\": (\"reference.wav\", ref_audio_data, \"audio/wav\")\n        },\n        stream=True,\n        timeout=120\n    )\n    \n    chunks = []\n    chunk_times = []\n    first_chunk_time = None\n    \n    for line in response.iter_lines():\n        if line:\n            line_str = line.decode('utf-8')\n            if line_str.startswith('data:'):\n                data = json.loads(line_str[5:].strip())\n                if data.get('type') == 'chunk':\n                    if first_chunk_time is None:\n                        first_chunk_time = time.time() - start_time\n                    chunks.append(data)\n                    chunk_times.append({\n                        'tts_time': data.get('tts_time', 0),\n                        'rvc_time': data.get('rvc_time', 0),\n                    })\n    \n    total_time = time.time() - start_time\n    \n    # Calculate metrics\n    total_tts = sum(c['tts_time'] for c in chunk_times)\n    total_rvc = sum(c['rvc_time'] for c in chunk_times)\n    \n    result = {\n        'text_length': len(text),\n        'word_count': len(text.split()),\n        'chunk_count': len(chunks),\n        'first_chunk_time': first_chunk_time,\n        'total_time': total_time,\n        'total_tts_time': total_tts,\n        'total_rvc_time': total_rvc,\n    }\n    benchmark_results.append(result)\n    \n    print(f\"  Chunks: {len(chunks)}\")\n    print(f\"  First chunk latency: {first_chunk_time:.2f}s\")\n    print(f\"  Total TTS time: {total_tts:.2f}s\")\n    print(f\"  Total RVC time: {total_rvc:.2f}s\")\n    print(f\"  Total time: {total_time:.2f}s\")\n\n# Summary\nprint(\"\\n\" + \"=\" * 60)\nprint(\"BENCHMARK SUMMARY\")\nprint(\"=\" * 60)\nprint(f\"{'Text Length':<15} {'Chunks':<10} {'1st Chunk':<12} {'TTS':<10} {'RVC':<10} {'Total':<10}\")\nprint(\"-\" * 60)\nfor r in benchmark_results:\n    print(f\"{r['text_length']:<15} {r['chunk_count']:<10} {r['first_chunk_time']:.2f}s{'':<6} {r['total_tts_time']:.2f}s{'':<4} {r['total_rvc_time']:.2f}s{'':<4} {r['total_time']:.2f}s\")\n\n# GPU memory\nprint(\"\\n\" + \"=\" * 60)\nprint(\"GPU MEMORY USAGE\")\nprint(\"=\" * 60)\n!nvidia-smi --query-gpu=name,memory.used,memory.total,utilization.gpu --format=csv"
  },
  {
   "cell_type": "code",
   "source": "# Cell 8.3: Save Benchmark Results (for documentation)\nimport os\nimport subprocess\nfrom datetime import datetime\n\n# Create test_results directory\nos.makedirs(\"test_results\", exist_ok=True)\n\n# Get GPU name\ngpu_name = subprocess.getoutput(\"nvidia-smi --query-gpu=name --format=csv,noheader\").strip()\n\n# Build benchmark markdown\nbenchmark_md = f\"\"\"# Voice Synthesis Benchmark Results\n\n**Date:** {datetime.now().strftime('%Y-%m-%d %H:%M')}\n**GPU:** {gpu_name}\n**Configuration:**\n- RVC Model: {RVC_MODEL}\n- RVC Workers: {RVC_WORKERS}\n- F0 Method: rmvpe\n- Index Rate: 1.0\n\n## SSE Streaming Endpoint Performance\n\n| Text Length | Words | Chunks | First Chunk | TTS Time | RVC Time | Total |\n|-------------|-------|--------|-------------|----------|----------|-------|\n\"\"\"\n\nfor r in benchmark_results:\n    benchmark_md += f\"| {r['text_length']} | {r['word_count']} | {r['chunk_count']} | {r['first_chunk_time']:.2f}s | {r['total_tts_time']:.2f}s | {r['total_rvc_time']:.2f}s | {r['total_time']:.2f}s |\\n\"\n\nbenchmark_md += \"\"\"\n## Key Metrics\n\n- **First Chunk Latency**: Time until first audio chunk is available for playback\n- **TTS Time**: Spark TTS inference time (per sentence)\n- **RVC Time**: Voice conversion time (per sentence)\n- **Total Time**: End-to-end processing time\n\n## GPU Memory Usage\n\n```\n\"\"\"\n\n# Add GPU info\ngpu_info = subprocess.getoutput(\"nvidia-smi --query-gpu=name,memory.used,memory.total,utilization.gpu --format=csv\")\nbenchmark_md += gpu_info + \"\\n```\\n\"\n\n# Save to file\nwith open(\"test_results/benchmarks.md\", \"w\") as f:\n    f.write(benchmark_md)\n\nprint(\"Benchmark results saved to: test_results/benchmarks.md\")\nprint(\"\\n\" + benchmark_md)",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Section 9: Shutdown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 9.1: Shutdown services\n",
    "import time\n",
    "\n",
    "print(\"Shutting down services...\")\n",
    "\n",
    "# Kill processes inside container\n",
    "!pkill -f tritonserver\n",
    "!pkill -f \"uvicorn.*voice_api\"\n",
    "!pkill -f \"udocker.*voice_server\"\n",
    "\n",
    "time.sleep(3)\n",
    "\n",
    "print(\"\\nGPU status after shutdown:\")\n",
    "!nvidia-smi"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}