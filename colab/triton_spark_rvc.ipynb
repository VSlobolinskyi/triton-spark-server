{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Triton Spark TTS + RVC Voice Conversion\n",
    "\n",
    "This notebook runs the full pipeline:\n",
    "1. **Triton Spark TTS** - Text-to-Speech (runs inside udocker container)\n",
    "2. **RVC Voice Conversion** - Voice cloning (runs on host Python with CUDA)\n",
    "\n",
    "## Architecture\n",
    "- Triton Server runs Spark TTS with TensorRT-LLM optimization (~10x faster)\n",
    "- RVC runs on host Python with direct CUDA access\n",
    "- Both share GPU memory via cross-process CUDA\n",
    "- Host Python communicates with Triton via gRPC (udocker shares host network)\n",
    "\n",
    "## Requirements\n",
    "- Google Colab with GPU runtime (T4 minimum, A100 recommended)\n",
    "- ~10GB disk space for models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Section 1: Setup Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 1.1: Initialize udocker for Triton container\n",
    "def udocker_init():\n",
    "    import os\n",
    "    if not os.path.exists(\"/home/user\"):\n",
    "        !pip install udocker > /dev/null\n",
    "        !udocker --allow-root install > /dev/null\n",
    "        !useradd -m user > /dev/null\n",
    "    print('Docker-in-Colab initialized')\n",
    "    def execute(command: str):\n",
    "        user_prompt = \"\\033[1;32muser@pc\\033[0m\"\n",
    "        print(f\"{user_prompt}$ udocker {command}\")\n",
    "        !su - user -c \"udocker $command\"\n",
    "    return execute\n",
    "\n",
    "udocker = udocker_init()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 1.2: Clone repository\n",
    "!git clone https://github.com/VSlobolinskyi/triton-spark-server.git\n",
    "%cd triton-spark-server\n",
    "# Switch to feature branch with RVC integration\n",
    "!git checkout feature/rvc-integration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 1.3: GPU Configuration\n",
    "import subprocess\n",
    "\n",
    "def detect_gpu():\n",
    "    \"\"\"Detect GPU and return configuration.\"\"\"\n",
    "    try:\n",
    "        result = subprocess.run(['nvidia-smi', '--query-gpu=name,memory.total', '--format=csv,noheader'],\n",
    "                               capture_output=True, text=True)\n",
    "        gpu_info = result.stdout.strip()\n",
    "        gpu_name = gpu_info.split(',')[0].strip()\n",
    "        gpu_mem = int(gpu_info.split(',')[1].replace('MiB', '').strip())\n",
    "        print(f\"Detected GPU: {gpu_name} ({gpu_mem}MB)\")\n",
    "        return gpu_name, gpu_mem\n",
    "    except:\n",
    "        print(\"No GPU detected!\")\n",
    "        return None, 0\n",
    "\n",
    "gpu_name, gpu_mem = detect_gpu()\n",
    "\n",
    "# udocker GPU options\n",
    "gpu_config = {\n",
    "    'all_options': '--device=/dev/nvidia0 --device=/dev/nvidiactl --device=/dev/nvidia-uvm --device=/dev/nvidia-uvm-tools'\n",
    "}\n",
    "print(\"GPU config ready\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Section 2: Setup Triton Container (Spark TTS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 2.1: Pull Triton Server image\n",
    "!udocker --allow-root pull nvcr.io/nvidia/tritonserver:25.02-trtllm-python-py3\n",
    "!udocker --allow-root create --name=triton_server nvcr.io/nvidia/tritonserver:25.02-trtllm-python-py3\n",
    "!udocker --allow-root setup --nvidia triton_server"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 2.2: Install dependencies inside container + download Spark model\n",
    "# Note: Repo is mounted at /workspace via --volume=$PWD:/workspace\n",
    "import os\n",
    "pwd = os.getcwd()\n",
    "\n",
    "install_cmd = f'''udocker --allow-root run \\\n",
    "    --hostauth --hostenv \\\n",
    "    {gpu_config['all_options']} \\\n",
    "    --volume={pwd}:/workspace \\\n",
    "    triton_server \\\n",
    "    /bin/bash -c \"apt-get update && apt-get install -y cmake && \\\n",
    "git clone https://github.com/pytorch/audio.git && cd audio && git checkout c670ad8 && USE_FFMPEG=0 PATH=/usr/local/cuda/bin:\\$PATH python3 setup.py develop && \\\n",
    "pip install einx==0.3.0 omegaconf==2.3.0 soundfile==0.12.1 soxr==0.5.0.post1 tritonclient librosa 'huggingface-hub>=0.24.0,<1.0' && \\\n",
    "python3 -c 'from huggingface_hub import snapshot_download; snapshot_download(repo_id=\\\"SparkAudio/Spark-TTS-0.5B\\\", local_dir=\\\"/workspace/pretrained_models/Spark-TTS-0.5B\\\")'\"\n",
    "'''\n",
    "\n",
    "!{install_cmd}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 2.3: Build TensorRT-LLM engine for Spark TTS\n",
    "import os\n",
    "pwd = os.getcwd()\n",
    "\n",
    "setup_cmd = f'''udocker --allow-root run \\\n",
    "    --hostauth --hostenv \\\n",
    "    {gpu_config['all_options']} \\\n",
    "    --env=PYTHONPATH=/workspace \\\n",
    "    --volume={pwd}:/workspace \\\n",
    "    triton_server \\\n",
    "    /bin/bash -c \"cd /workspace/runtime/triton_trtllm && bash run.sh 1 2 offline\"'''\n",
    "\n",
    "!{setup_cmd}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Section 3: Setup RVC on Host Python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 3.1: Install RVC dependencies on host\n",
    "# Colab has Python 3.10 which is compatible with our requirements\n",
    "\n",
    "# Install fairseq from git (required for HuBERT)\n",
    "!pip install -q git+https://github.com/One-sixth/fairseq.git\n",
    "\n",
    "# Install main requirements\n",
    "!pip install -q -r requirements.txt\n",
    "\n",
    "print(\"RVC dependencies installed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 3.2: Download RVC assets (HuBERT, RMVPE)\n",
    "!python tools/download_all_assets.py --rvc-only --skip-pretrained"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 3.3: Download RVC voice model (SilverWolf example)\n",
    "# You can replace this URL with your own RVC model\n",
    "RVC_MODEL_URL = \"https://huggingface.co/Juneuarie/SilverWolfEN/resolve/main/SilverWolf.zip\"\n",
    "!python tools/download_all_assets.py --rvc-model \"{RVC_MODEL_URL}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 3.4: Test RVC initialization\n",
    "import sys\n",
    "sys.path.insert(0, '.')\n",
    "\n",
    "from rvc import init_rvc, get_config\n",
    "\n",
    "init_rvc()\n",
    "config = get_config()\n",
    "print(f\"RVC initialized:\")\n",
    "print(f\"  Device: {config.device}\")\n",
    "print(f\"  Half precision: {config.is_half}\")\n",
    "print(f\"  GPU: {config.gpu_name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Section 4: Start Triton Server"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 4.1: Start Triton server in background\n",
    "# Note: udocker shares host network, so Triton will be accessible at localhost:8001\n",
    "import subprocess\n",
    "import time\n",
    "import os\n",
    "\n",
    "pwd = os.getcwd()\n",
    "\n",
    "server_cmd = f'''udocker --allow-root run \\\n",
    "    --hostauth --hostenv \\\n",
    "    {gpu_config['all_options']} \\\n",
    "    --env=PYTHONPATH=/workspace \\\n",
    "    --volume={pwd}:/workspace \\\n",
    "    triton_server \\\n",
    "    /bin/bash -c \"cd /workspace/runtime/triton_trtllm && tritonserver --model-repository=./model_repo_test\"'''\n",
    "\n",
    "# Run in background\n",
    "process = subprocess.Popen(\n",
    "    f\"nohup {server_cmd} > server_log.txt 2>&1 &\",\n",
    "    shell=True\n",
    ")\n",
    "\n",
    "print(\"Triton server starting...\")\n",
    "print(\"Waiting 45 seconds for models to load...\")\n",
    "time.sleep(45)\n",
    "!tail -30 server_log.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 4.2: Test Triton connection from host Python\n",
    "# This verifies that host can communicate with Triton via gRPC\n",
    "from rvc.triton_client import TritonSparkClient\n",
    "\n",
    "client = TritonSparkClient(server_addr=\"localhost\", server_port=8001)\n",
    "\n",
    "if client.is_server_ready():\n",
    "    print(\"Triton server is ready!\")\n",
    "else:\n",
    "    print(\"Triton server not ready - check server_log.txt\")\n",
    "\n",
    "if client.is_model_ready():\n",
    "    print(\"Spark TTS model is loaded!\")\n",
    "else:\n",
    "    print(\"Spark TTS model not loaded - check server_log.txt\")\n",
    "\n",
    "client.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Section 5: Upload Reference Audio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 5.1: Upload reference audio for voice cloning\n",
    "import os\n",
    "import soundfile as sf\n",
    "from scipy import signal\n",
    "from google.colab import files\n",
    "\n",
    "# Create directories\n",
    "!mkdir -p references TEMP/tts TEMP/rvc TEMP/test\n",
    "\n",
    "# Upload reference audio\n",
    "print(\"Please upload a reference audio file (.wav format):\")\n",
    "uploaded = files.upload()\n",
    "\n",
    "# Process uploaded file\n",
    "reference_audio = list(uploaded.keys())[0]\n",
    "references_path = os.path.join(\"references\", reference_audio)\n",
    "\n",
    "with open(references_path, \"wb\") as f:\n",
    "    f.write(uploaded[reference_audio])\n",
    "print(f\"Saved to {references_path}\")\n",
    "\n",
    "# Resample to 16kHz for Spark TTS\n",
    "audio, sr = sf.read(references_path)\n",
    "print(f\"Original: {len(audio)/sr:.2f}s @ {sr}Hz\")\n",
    "\n",
    "if sr != 16000:\n",
    "    target_sr = 16000\n",
    "    num_samples = int(len(audio) * (target_sr / sr))\n",
    "    resampled_audio = signal.resample(audio, num_samples)\n",
    "    \n",
    "    base_name = os.path.splitext(reference_audio)[0]\n",
    "    reference_audio_16k = os.path.join(\"references\", f\"{base_name}_16k.wav\")\n",
    "    sf.write(reference_audio_16k, resampled_audio, target_sr)\n",
    "    print(f\"Resampled to 16kHz: {reference_audio_16k}\")\n",
    "else:\n",
    "    reference_audio_16k = references_path\n",
    "    print(f\"Already 16kHz, using: {reference_audio_16k}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Section 6: Run Full Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 6.1: Configuration\n",
    "# Modify these settings as needed\n",
    "\n",
    "# Text to synthesize\n",
    "TARGET_TEXT = \"Hello! This is a test of the Triton Spark TTS and RVC voice conversion pipeline. The voice should sound like the reference audio.\"\n",
    "\n",
    "# Reference text (can be empty for offline mode)\n",
    "REFERENCE_TEXT = \"\"\n",
    "\n",
    "# RVC model name (from assets/weights/)\n",
    "RVC_MODEL = \"SilverWolf.pth\"\n",
    "\n",
    "# Pitch shift in semitones (0 = no change)\n",
    "PITCH_SHIFT = 0\n",
    "\n",
    "# F0 extraction method (rmvpe is best quality)\n",
    "F0_METHOD = \"rmvpe\"\n",
    "\n",
    "print(f\"Configuration:\")\n",
    "print(f\"  Text: {TARGET_TEXT[:50]}...\")\n",
    "print(f\"  RVC Model: {RVC_MODEL}\")\n",
    "print(f\"  Pitch Shift: {PITCH_SHIFT}\")\n",
    "print(f\"  F0 Method: {F0_METHOD}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 6.2: Run full pipeline test\n",
    "import subprocess\n",
    "\n",
    "cmd = [\n",
    "    \"python\", \"tools/test_pipeline.py\",\n",
    "    \"--triton-addr\", \"localhost\",\n",
    "    \"--triton-port\", \"8001\",\n",
    "    \"--prompt-audio\", reference_audio_16k,\n",
    "    \"--prompt-text\", REFERENCE_TEXT,\n",
    "    \"--text\", TARGET_TEXT,\n",
    "    \"--rvc-model\", RVC_MODEL,\n",
    "    \"--pitch-shift\", str(PITCH_SHIFT),\n",
    "    \"--f0-method\", F0_METHOD,\n",
    "    \"--output-dir\", \"./TEMP/test\"\n",
    "]\n",
    "\n",
    "result = subprocess.run(cmd)\n",
    "print(f\"\\nPipeline finished with code: {result.returncode}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 6.3: Play output audio\n",
    "from IPython.display import Audio, display\n",
    "import os\n",
    "\n",
    "tts_path = \"TEMP/test/tts_output.wav\"\n",
    "rvc_path = \"TEMP/test/rvc_output.wav\"\n",
    "\n",
    "if os.path.exists(tts_path):\n",
    "    print(\"TTS Output (before RVC):\")\n",
    "    display(Audio(tts_path))\n",
    "else:\n",
    "    print(f\"TTS output not found at {tts_path}\")\n",
    "\n",
    "if os.path.exists(rvc_path):\n",
    "    print(\"\\nRVC Output (final voice):\")\n",
    "    display(Audio(rvc_path))\n",
    "else:\n",
    "    print(f\"RVC output not found at {rvc_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Section 7: Manual Pipeline Control (Optional)\n",
    "\n",
    "Use these cells for more control over individual steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 7.1: Run TTS only\n",
    "import time\n",
    "import soundfile as sf\n",
    "from rvc.triton_client import TritonSparkClient\n",
    "\n",
    "client = TritonSparkClient(server_addr=\"localhost\", server_port=8001)\n",
    "\n",
    "text = \"This is a test of Triton Spark TTS without voice conversion.\"\n",
    "\n",
    "start = time.time()\n",
    "wav = client.inference(\n",
    "    text=text,\n",
    "    prompt_speech=reference_audio_16k,\n",
    "    prompt_text=\"\",\n",
    ")\n",
    "elapsed = time.time() - start\n",
    "\n",
    "duration = len(wav) / 16000\n",
    "print(f\"Generated {duration:.2f}s of audio in {elapsed:.2f}s (RTF: {elapsed/duration:.2f})\")\n",
    "\n",
    "sf.write(\"TEMP/tts/tts_only.wav\", wav, 16000)\n",
    "client.close()\n",
    "\n",
    "from IPython.display import Audio\n",
    "Audio(\"TEMP/tts/tts_only.wav\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 7.2: Run RVC only (on existing audio)\n",
    "import time\n",
    "import soundfile as sf\n",
    "from rvc import init_rvc, load_model, convert_audio, is_initialized\n",
    "\n",
    "if not is_initialized():\n",
    "    init_rvc()\n",
    "\n",
    "# Load model\n",
    "model_info = load_model(\"SilverWolf.pth\")\n",
    "print(f\"Loaded model: version={model_info.get('version')}, sr={model_info.get('tgt_sr')}\")\n",
    "\n",
    "# Convert\n",
    "input_audio = \"TEMP/tts/tts_only.wav\"  # Use TTS output from previous cell\n",
    "\n",
    "start = time.time()\n",
    "info, (sr, audio) = convert_audio(\n",
    "    audio_path=input_audio,\n",
    "    pitch_shift=0,\n",
    "    f0_method=\"rmvpe\",\n",
    ")\n",
    "elapsed = time.time() - start\n",
    "\n",
    "duration = len(audio) / sr\n",
    "print(f\"Converted {duration:.2f}s of audio in {elapsed:.2f}s\")\n",
    "\n",
    "sf.write(\"TEMP/rvc/rvc_only.wav\", audio, sr)\n",
    "\n",
    "from IPython.display import Audio\n",
    "Audio(\"TEMP/rvc/rvc_only.wav\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Section 8: Download Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 8.1: Download output files\n",
    "from google.colab import files\n",
    "import os\n",
    "\n",
    "# Download final RVC output\n",
    "rvc_path = \"TEMP/test/rvc_output.wav\"\n",
    "if os.path.exists(rvc_path):\n",
    "    files.download(rvc_path)\n",
    "else:\n",
    "    print(f\"File not found: {rvc_path}\")\n",
    "\n",
    "# Optionally download TTS output too\n",
    "# files.download(\"TEMP/test/tts_output.wav\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Troubleshooting\n",
    "\n",
    "### Check server logs\n",
    "```python\n",
    "!tail -50 server_log.txt\n",
    "```\n",
    "\n",
    "### Check available RVC models\n",
    "```python\n",
    "!ls -la assets/weights/\n",
    "!ls -la logs/\n",
    "```\n",
    "\n",
    "### Memory issues\n",
    "- Restart runtime (Runtime -> Restart Runtime) and re-run\n",
    "- Use a GPU with more memory (A100 if available)\n",
    "\n",
    "### Network issues (Triton connection)\n",
    "- udocker shares host network, so localhost:8001 should work\n",
    "- Check if server started: `!ps aux | grep triton`"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
