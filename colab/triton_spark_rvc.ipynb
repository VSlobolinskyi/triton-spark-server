{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Triton Spark TTS + RVC Voice Conversion\n",
    "\n",
    "This notebook runs the full pipeline:\n",
    "1. **Triton Spark TTS** - Text-to-Speech (runs inside udocker container)\n",
    "2. **RVC Voice Conversion** - Voice cloning (runs on host Python with CUDA)\n",
    "\n",
    "## Architecture\n",
    "- Triton Server runs Spark TTS with TensorRT-LLM optimization (~10x faster)\n",
    "- RVC runs on host Python with direct CUDA access\n",
    "- Both share GPU memory via cross-process CUDA\n",
    "- Host Python communicates with Triton via gRPC (udocker shares host network)\n",
    "\n",
    "## Requirements\n",
    "- Google Colab with GPU runtime (T4 minimum, A100 recommended)\n",
    "- ~10GB disk space for models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Section 1: Setup Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 1.1: Initialize udocker for Triton container\n",
    "def udocker_init():\n",
    "    import os\n",
    "    if not os.path.exists(\"/home/user\"):\n",
    "        !pip install udocker > /dev/null\n",
    "        !udocker --allow-root install > /dev/null\n",
    "        !useradd -m user > /dev/null\n",
    "    print('Docker-in-Colab initialized')\n",
    "    def execute(command: str):\n",
    "        user_prompt = \"\\033[1;32muser@pc\\033[0m\"\n",
    "        print(f\"{user_prompt}$ udocker {command}\")\n",
    "        !su - user -c \"udocker $command\"\n",
    "    return execute\n",
    "\n",
    "udocker = udocker_init()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 1.2: Clone repository\n",
    "!git clone https://github.com/VSlobolinskyi/triton-spark-server.git\n",
    "%cd triton-spark-server\n",
    "# Switch to feature branch with RVC integration\n",
    "!git checkout feature/rvc-integration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 1.3: GPU Configuration\n",
    "# Detect NVIDIA/CUDA paths and create proper volume/env mappings for udocker\n",
    "\n",
    "def detect_gpu_paths():\n",
    "    import os\n",
    "    import subprocess\n",
    "\n",
    "    # Detect critical paths\n",
    "    paths = {}\n",
    "    paths['nvidia_smi'] = subprocess.getoutput('which nvidia-smi')\n",
    "    paths['cuda_dir'] = subprocess.getoutput(\"find /usr -path '*/cuda*' -type d -maxdepth 3 | grep -v 'targets' | head -1\")\n",
    "    paths['nvidia_lib_dir'] = subprocess.getoutput(\"find /usr -name 'libcuda.so*' -o -name 'libnvidia-ml.so*' | grep -v 'stubs' | xargs dirname | sort -u | head -1\")\n",
    "    paths['ld_library_path'] = f\"{paths['nvidia_lib_dir']}:{paths['cuda_dir']}/lib64:{paths['cuda_dir']}/compat\"\n",
    "\n",
    "    # Get basic NVIDIA devices that we know work\n",
    "    basic_devices = ['/dev/nvidia0', '/dev/nvidiactl', '/dev/nvidia-uvm']\n",
    "\n",
    "    # Create volume mappings\n",
    "    volumes = [\n",
    "        f\"--volume={paths['nvidia_smi']}:{paths['nvidia_smi']}\",\n",
    "        f\"--volume={paths['nvidia_lib_dir']}:{paths['nvidia_lib_dir']}\",\n",
    "        f\"--volume={paths['cuda_dir']}:{paths['cuda_dir']}\"\n",
    "    ]\n",
    "\n",
    "    # Add only the basic device mappings that we know work\n",
    "    for device in basic_devices:\n",
    "        if os.path.exists(device):\n",
    "            volumes.append(f\"--volume={device}:{device}\")\n",
    "\n",
    "    # Create environment variables - add TensorRT path within container and include Triton Server path\n",
    "    env_vars = [\n",
    "        f\"--env=LD_LIBRARY_PATH={paths['ld_library_path']}:/usr/local/tensorrt/targets/x86_64-linux-gnu/lib:$LD_LIBRARY_PATH\",\n",
    "        f\"--env=PATH=/opt/tritonserver/bin:{paths['cuda_dir']}/bin:/usr/bin:$PATH\",\n",
    "        \"--env=NVIDIA_VISIBLE_DEVICES=all\",\n",
    "        \"--env=NVIDIA_DRIVER_CAPABILITIES=compute,utility\"\n",
    "    ]\n",
    "\n",
    "    return {\n",
    "        'paths': paths,\n",
    "        'volumes': volumes,\n",
    "        'env_vars': env_vars,\n",
    "        'all_options': ' '.join(volumes + env_vars)\n",
    "    }\n",
    "\n",
    "# Get GPU configuration\n",
    "gpu_config = detect_gpu_paths()\n",
    "\n",
    "# Print the configuration\n",
    "print(\"Detected NVIDIA/CUDA paths:\")\n",
    "for k, v in gpu_config['paths'].items():\n",
    "    print(f\"  {k}: {v}\")\n",
    "\n",
    "print(\"\\nVolume mappings:\")\n",
    "for v in gpu_config['volumes']:\n",
    "    print(f\"  {v}\")\n",
    "\n",
    "print(\"\\nEnvironment variables:\")\n",
    "for e in gpu_config['env_vars']:\n",
    "    print(f\"  {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Section 2: Setup Triton Container (Spark TTS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 2.1: Pull Triton Server image\n",
    "!udocker --allow-root pull nvcr.io/nvidia/tritonserver:25.02-trtllm-python-py3\n",
    "!udocker --allow-root create --name=triton_server nvcr.io/nvidia/tritonserver:25.02-trtllm-python-py3\n",
    "!udocker --allow-root setup --nvidia triton_server"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 2.2: Install dependencies inside container\n",
    "# Note: Repo is mounted at /workspace via --volume=$PWD:/workspace\n",
    "import os\n",
    "pwd = os.getcwd()\n",
    "\n",
    "install_cmd = f'''udocker --allow-root run \\\n",
    "    --hostauth --hostenv \\\n",
    "    {gpu_config['all_options']} \\\n",
    "    --volume={pwd}:/workspace \\\n",
    "    triton_server \\\n",
    "    /bin/bash -c \"apt-get update && apt-get install -y cmake && \\\n",
    "git clone https://github.com/pytorch/audio.git && cd audio && git checkout c670ad8 && USE_FFMPEG=0 PATH=/usr/local/cuda/bin:\\$PATH python3 setup.py develop && \\\n",
    "pip install einx==0.3.0 omegaconf==2.3.0 soundfile==0.12.1 soxr==0.5.0.post1 tritonclient librosa 'huggingface-hub>=0.24.0,<1.0'\"\n",
    "'''\n",
    "\n",
    "!{install_cmd}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 2.3: Build TensorRT-LLM engine for Spark TTS\n",
    "# Stage 0: Download model (if not already downloaded in 2.2)\n",
    "# Stage 1: Convert checkpoint to TensorRT weights\n",
    "# Stage 2: Create model repository\n",
    "import os\n",
    "pwd = os.getcwd()\n",
    "\n",
    "setup_cmd = f'''udocker --allow-root run \\\n",
    "    --hostauth --hostenv \\\n",
    "    {gpu_config['all_options']} \\\n",
    "    --env=PYTHONPATH=/workspace \\\n",
    "    --volume={pwd}:/workspace \\\n",
    "    triton_server \\\n",
    "    /bin/bash -c \"cd /workspace/runtime/triton_trtllm && bash run.sh 0 2 offline\"'''\n",
    "\n",
    "!{setup_cmd}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Section 3: Setup RVC on Host Python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Cell 3.1: Install RVC dependencies on host\n\n# Install fairseq from git (required for HuBERT)\n!pip install -q git+https://github.com/One-sixth/fairseq.git\n\n# Install main requirements\n!pip install -q -r requirements.txt\n\nprint(\"RVC dependencies installed\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Cell 3.2: Download RVC assets (HuBERT, RMVPE)\n!python tools/download_all_assets.py --rvc-only"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 3.3: Download RVC voice model (SilverWolf example)\n",
    "# You can replace this URL with your own RVC model\n",
    "RVC_MODEL_URL = \"https://huggingface.co/Juneuarie/SilverWolfEN/resolve/main/SilverWolf.zip\"\n",
    "!python tools/download_all_assets.py --rvc-model \"{RVC_MODEL_URL}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Cell 3.4: Test RVC initialization\n!python tools/init_rvc.py"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Section 4: Start Triton Server"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 4.1: Start Triton server in background\n",
    "# Note: udocker shares host network, so Triton will be accessible at localhost:8001\n",
    "import subprocess\n",
    "import time\n",
    "import os\n",
    "\n",
    "pwd = os.getcwd()\n",
    "\n",
    "server_cmd = f'''udocker --allow-root run \\\n",
    "    --hostauth --hostenv \\\n",
    "    {gpu_config['all_options']} \\\n",
    "    --env=PYTHONPATH=/workspace \\\n",
    "    --volume={pwd}:/workspace \\\n",
    "    triton_server \\\n",
    "    /bin/bash -c \"cd /workspace/runtime/triton_trtllm && tritonserver --model-repository=./model_repo_test\"'''\n",
    "\n",
    "# Run in background\n",
    "process = subprocess.Popen(\n",
    "    f\"nohup {server_cmd} > server_log.txt 2>&1 &\",\n",
    "    shell=True\n",
    ")\n",
    "\n",
    "print(\"Triton server starting...\")\n",
    "print(\"Waiting 45 seconds for models to load...\")\n",
    "time.sleep(45)\n",
    "!tail -30 server_log.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Cell 4.2: Test Triton connection from host Python\n!python tools/test_triton_connection.py --addr localhost --port 8001"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Section 5: Upload Reference Audio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 5.1: Upload reference audio for voice cloning\n",
    "import os\n",
    "import soundfile as sf\n",
    "from scipy import signal\n",
    "from google.colab import files\n",
    "\n",
    "# Create directories\n",
    "!mkdir -p references TEMP/tts TEMP/rvc TEMP/test\n",
    "\n",
    "# Upload reference audio\n",
    "print(\"Please upload a reference audio file (.wav format):\")\n",
    "uploaded = files.upload()\n",
    "\n",
    "# Process uploaded file\n",
    "reference_audio = list(uploaded.keys())[0]\n",
    "references_path = os.path.join(\"references\", reference_audio)\n",
    "\n",
    "with open(references_path, \"wb\") as f:\n",
    "    f.write(uploaded[reference_audio])\n",
    "print(f\"Saved to {references_path}\")\n",
    "\n",
    "# Resample to 16kHz for Spark TTS\n",
    "audio, sr = sf.read(references_path)\n",
    "print(f\"Original: {len(audio)/sr:.2f}s @ {sr}Hz\")\n",
    "\n",
    "if sr != 16000:\n",
    "    target_sr = 16000\n",
    "    num_samples = int(len(audio) * (target_sr / sr))\n",
    "    resampled_audio = signal.resample(audio, num_samples)\n",
    "    \n",
    "    base_name = os.path.splitext(reference_audio)[0]\n",
    "    reference_audio_16k = os.path.join(\"references\", f\"{base_name}_16k.wav\")\n",
    "    sf.write(reference_audio_16k, resampled_audio, target_sr)\n",
    "    print(f\"Resampled to 16kHz: {reference_audio_16k}\")\n",
    "else:\n",
    "    reference_audio_16k = references_path\n",
    "    print(f\"Already 16kHz, using: {reference_audio_16k}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Section 6: Run Full Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 6.1: Configuration\n",
    "# Modify these settings as needed\n",
    "\n",
    "# Text to synthesize\n",
    "TARGET_TEXT = \"Hello! This is a test of the Triton Spark TTS and RVC voice conversion pipeline. The voice should sound like the reference audio.\"\n",
    "\n",
    "# Reference text (can be empty for offline mode)\n",
    "REFERENCE_TEXT = \"\"\n",
    "\n",
    "# RVC model name (from assets/weights/)\n",
    "RVC_MODEL = \"SilverWolf.pth\"\n",
    "\n",
    "# Pitch shift in semitones (0 = no change)\n",
    "PITCH_SHIFT = 0\n",
    "\n",
    "# F0 extraction method (rmvpe is best quality)\n",
    "F0_METHOD = \"rmvpe\"\n",
    "\n",
    "print(f\"Configuration:\")\n",
    "print(f\"  Text: {TARGET_TEXT[:50]}...\")\n",
    "print(f\"  RVC Model: {RVC_MODEL}\")\n",
    "print(f\"  Pitch Shift: {PITCH_SHIFT}\")\n",
    "print(f\"  F0 Method: {F0_METHOD}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 6.2: Run full pipeline test\n",
    "import subprocess\n",
    "\n",
    "cmd = [\n",
    "    \"python\", \"tools/test_pipeline.py\",\n",
    "    \"--triton-addr\", \"localhost\",\n",
    "    \"--triton-port\", \"8001\",\n",
    "    \"--prompt-audio\", reference_audio_16k,\n",
    "    \"--prompt-text\", REFERENCE_TEXT,\n",
    "    \"--text\", TARGET_TEXT,\n",
    "    \"--rvc-model\", RVC_MODEL,\n",
    "    \"--pitch-shift\", str(PITCH_SHIFT),\n",
    "    \"--f0-method\", F0_METHOD,\n",
    "    \"--output-dir\", \"./TEMP/test\"\n",
    "]\n",
    "\n",
    "result = subprocess.run(cmd)\n",
    "print(f\"\\nPipeline finished with code: {result.returncode}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 6.3: Play output audio\n",
    "from IPython.display import Audio, display\n",
    "import os\n",
    "\n",
    "tts_path = \"TEMP/test/tts_output.wav\"\n",
    "rvc_path = \"TEMP/test/rvc_output.wav\"\n",
    "\n",
    "if os.path.exists(tts_path):\n",
    "    print(\"TTS Output (before RVC):\")\n",
    "    display(Audio(tts_path))\n",
    "else:\n",
    "    print(f\"TTS output not found at {tts_path}\")\n",
    "\n",
    "if os.path.exists(rvc_path):\n",
    "    print(\"\\nRVC Output (final voice):\")\n",
    "    display(Audio(rvc_path))\n",
    "else:\n",
    "    print(f\"RVC output not found at {rvc_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Section 7: Manual Pipeline Control (Optional)\n",
    "\n",
    "Use these cells for more control over individual steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Cell 7.1: Run TTS only\ntext = \"This is a test of Triton Spark TTS without voice conversion.\"\n\n!python tools/run_tts.py \\\n    --addr localhost \\\n    --port 8001 \\\n    --text \"{text}\" \\\n    --reference-audio \"{reference_audio_16k}\" \\\n    --output \"TEMP/tts/tts_only.wav\"\n\nfrom IPython.display import Audio\nAudio(\"TEMP/tts/tts_only.wav\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Cell 7.2: Run RVC only (on existing audio)\n!python tools/run_rvc.py \\\n    --input \"TEMP/tts/tts_only.wav\" \\\n    --model \"SilverWolf.pth\" \\\n    --output \"TEMP/rvc/rvc_only.wav\" \\\n    --pitch-shift 0 \\\n    --f0-method \"rmvpe\"\n\nfrom IPython.display import Audio\nAudio(\"TEMP/rvc/rvc_only.wav\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Section 8: Download Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 8.1: Download output files\n",
    "from google.colab import files\n",
    "import os\n",
    "\n",
    "# Download final RVC output\n",
    "rvc_path = \"TEMP/test/rvc_output.wav\"\n",
    "if os.path.exists(rvc_path):\n",
    "    files.download(rvc_path)\n",
    "else:\n",
    "    print(f\"File not found: {rvc_path}\")\n",
    "\n",
    "# Optionally download TTS output too\n",
    "# files.download(\"TEMP/test/tts_output.wav\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Troubleshooting\n",
    "\n",
    "### Check server logs\n",
    "```python\n",
    "!tail -50 server_log.txt\n",
    "```\n",
    "\n",
    "### Check available RVC models\n",
    "```python\n",
    "!ls -la assets/weights/\n",
    "!ls -la logs/\n",
    "```\n",
    "\n",
    "### Memory issues\n",
    "- Restart runtime (Runtime -> Restart Runtime) and re-run\n",
    "- Use a GPU with more memory (A100 if available)\n",
    "\n",
    "### Network issues (Triton connection)\n",
    "- udocker shares host network, so localhost:8001 should work\n",
    "- Check if server started: `!ps aux | grep triton`"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}